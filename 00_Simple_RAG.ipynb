{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# install dependencies:\n"
      ],
      "metadata": {
        "id": "4ubdyFPHsy-u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiC2Lnuxr_oJ"
      },
      "outputs": [],
      "source": [
        "! pip install chromadb langchain langchain_community langchainhub langchain-core\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip -q install sentence_transformers"
      ],
      "metadata": {
        "id": "Hqnc3N2nsIKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://ollama.ai/install.sh | sh"
      ],
      "metadata": {
        "id": "3HLSatxzsIUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-xterm\n",
        "%load_ext colabxterm"
      ],
      "metadata": {
        "id": "krCgbREusIZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Import packages:"
      ],
      "metadata": {
        "id": "0NEDLOP0tHRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.llms import Ollama\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n"
      ],
      "metadata": {
        "id": "dUgy-cvlsIeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Documents & and index them:"
      ],
      "metadata": {
        "id": "FfQPYcmStMIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Documents\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "docs = loader.load()\n"
      ],
      "metadata": {
        "id": "6g2npt1ZsIkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n"
      ],
      "metadata": {
        "id": "jGQ-6rvisIqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-base\")\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=splits,\n",
        "                                    embedding=embeddings)\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n"
      ],
      "metadata": {
        "id": "vMo5CKbAsItz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the Terminal inside the NoteBook:"
      ],
      "metadata": {
        "id": "Hqyo28NJtUkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Then we need to install **ollama** inside of the running terminal:\n",
        "```\n",
        "curl https://ollama.ai/install.sh | sh\n",
        "```\n",
        "* When Ollama is installed we can now serve it and pull a LLM of choice:\n",
        "```\n",
        "ollama serve & ollama pull llama3\n",
        "```\n",
        "* Here I pick `llama3` but you can go with any model you like.\n",
        "* The final step is to run the model:\n",
        "``` ollama run llama3\n",
        "```\n",
        "    - this step will take a bit of time..  \n",
        "**PS: all of the 3 steps above should be executed inside of terminal window**    "
      ],
      "metadata": {
        "id": "nIRN2dIJtf24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm\n"
      ],
      "metadata": {
        "id": "PbsaU4yWsIzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Prompt and Generation:"
      ],
      "metadata": {
        "id": "iApZTJKAtlax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "# LLM\n",
        "llm = ChatOllama(model='llama3', format=\"json\", temperature=0)\n"
      ],
      "metadata": {
        "id": "26y2JAc-sI2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Post-processing\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n"
      ],
      "metadata": {
        "id": "3NGXtC2HsI6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Chain\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "RUPwU7d2sJEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question\n",
        "rag_chain.invoke(\"What is Task Decomposition?\")\n"
      ],
      "metadata": {
        "id": "mQNzFKIxsJQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CC5jE9kqsJY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TEgJwSITsJgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Leq6ohXssJlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GEsBEmpbsJpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wpFKLpPbsJwS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}